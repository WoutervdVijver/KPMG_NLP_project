{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK_nl_sample_tokenize_and_lemmatize.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Attempting to tokenize"
      ],
      "metadata": {
        "id": "6sCRiqlgdRk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing file handling library and NLP library\n",
        "import os\n",
        "import nltk"
      ],
      "metadata": {
        "id": "zpWPH0redJcv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(os.getcwd()+ '/drive/MyDrive/nl_sample.txt','rt')\n",
        "raw_text = file.read()\n",
        "file.close()"
      ],
      "metadata": {
        "id": "ATaJw2lZeJ3m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing\n",
        "nltk.download('punkt')\n",
        "\n",
        "token_list1 = nltk.word_tokenize(raw_text)\n",
        "print(token_list1[0:20],'\\n')\n",
        "print('Total tokens : ', len(token_list1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRv-ORY6XY1T",
        "outputId": "5e3c99c8-20da-45ca-b67f-d19877530d80"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['Publicatie', ':', '2020-01-29', 'Numac', ':', '2020020106', 'MINISTERIE', 'VAN', 'DE', 'FRANSE', 'GEMEENSCHAP', '20', 'DECEMBER', '2019', '.', '-', 'Ministerieel', 'besluit', 'tot', 'goedkeuring'] \n",
            "\n",
            "Total tokens :  574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion of all words to lower case\n",
        "token_list2 = [word.lower() for word in token_list1]\n",
        "print(token_list2[0:20],'\\n')\n",
        "print('Total tokens : ', len(token_list2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyT5-J1afav6",
        "outputId": "485341a6-eca3-4cf8-b027-149acab63672"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['publicatie', ':', '2020-01-29', 'numac', ':', '2020020106', 'ministerie', 'van', 'de', 'franse', 'gemeenschap', '20', 'december', '2019', '.', '-', 'ministerieel', 'besluit', 'tot', 'goedkeuring'] \n",
            "\n",
            "Total tokens :  574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation\n",
        "from nltk.tokenize import punkt\n",
        "\n",
        "token_list2 = list(filter(lambda token : punkt.PunktToken(token).is_non_punct,token_list1))\n",
        "print(token_list2[0:20],\"\\n\")\n",
        "print(\"Total tokens : \", len(token_list2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP8VSzdBgAgx",
        "outputId": "6a0aecf2-c23e-47b3-b561-e8657744ab57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Publicatie', '2020-01-29', 'Numac', '2020020106', 'MINISTERIE', 'VAN', 'DE', 'FRANSE', 'GEMEENSCHAP', '20', 'DECEMBER', '2019', 'Ministerieel', 'besluit', 'tot', 'goedkeuring', 'van', 'het', 'referentiedossier', 'van'] \n",
            "\n",
            "Total tokens :  487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stop words\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "token_list3 = list(filter(lambda token: token not in stopwords.words(\"english\"),token_list2))\n",
        "print(token_list3[0:20],\"\\n\")\n",
        "print(\"Total tokens : \", len(token_list3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-40_nL1gocN",
        "outputId": "bab23a99-cb67-43c1-8a6a-98d9c6c53f26"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['Publicatie', '2020-01-29', 'Numac', '2020020106', 'MINISTERIE', 'VAN', 'DE', 'FRANSE', 'GEMEENSCHAP', '20', 'DECEMBER', '2019', 'Ministerieel', 'besluit', 'tot', 'goedkeuring', 'van', 'het', 'referentiedossier', 'van'] \n",
            "\n",
            "Total tokens :  484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization of words"
      ],
      "metadata": {
        "id": "bQuUGQvAhC3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "token_list4 = [lemmatizer.lemmatize(word) for word in token_list3]\n",
        "print(token_list4[0:20],\"\\n\")\n",
        "print(\"Total tokens : \", len(token_list4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-miiJdRhLpL",
        "outputId": "d17f6b8a-f60f-4c4f-ed3e-17d95a62b0ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "['Publicatie', '2020-01-29', 'Numac', '2020020106', 'MINISTERIE', 'VAN', 'DE', 'FRANSE', 'GEMEENSCHAP', '20', 'DECEMBER', '2019', 'Ministerieel', 'besluit', 'tot', 'goedkeuring', 'van', 'het', 'referentiedossier', 'van'] \n",
            "\n",
            "Total tokens :  484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attempt to Lemmatize a sentence"
      ],
      "metadata": {
        "id": "teayI_ljgIf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pprint import pprint\n",
        " \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "#text = \"I have gone to the meet someone for the most important meeting of my life. I feel my best feelings right now.\"\n",
        "\n",
        "def lemmetize(words):\n",
        "     a = []\n",
        "     tokens = word_tokenize(words)\n",
        "     for token in tokens:\n",
        "          lemmetized_word = lemmatizer.lemmatize(token)\n",
        "          a.append(lemmetized_word)\n",
        "     print({a[i] : tokens[i] for i in range(len(a))})\n",
        "\n",
        "#lemmetize_print(\"studies studying cries cry\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrxnuhuZX8uB",
        "outputId": "69cf7cd4-f1a2-4837-eda7-f27b0e5f37d3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = 'Gelet op de wetten op het toekennen van de academische graden en het programma van de universitaire examens, gecoördineerd bij het besluit van de Regent van 31 december 1949, inzonderheid op artikel 6, gewijzigd bij artikel 124 van het decreet van de Franse Gemeenschap van 16 april 1991 houdende organisatie van het onderwijs voor sociale promotie'\n",
        "\n",
        "lemmetize(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DslrCWZsYESd",
        "outputId": "2154958c-3ff6-4068-fca2-b1c071e8554f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Gelet': 'Gelet', 'op': 'op', 'de': 'de', 'wetten': 'wetten', 'het': 'het', 'toekennen': 'toekennen', 'van': 'van', 'academische': 'academische', 'graden': 'graden', 'en': 'en', 'programma': 'programma', 'universitaire': 'universitaire', 'examen': 'examens', ',': ',', 'gecoördineerd': 'gecoördineerd', 'bij': 'bij', 'besluit': 'besluit', 'Regent': 'Regent', '31': '31', 'december': 'december', '1949': '1949', 'inzonderheid': 'inzonderheid', 'artikel': 'artikel', '6': '6', 'gewijzigd': 'gewijzigd', '124': '124', 'decreet': 'decreet', 'Franse': 'Franse', 'Gemeenschap': 'Gemeenschap', '16': '16', 'april': 'april', '1991': '1991', 'houdende': 'houdende', 'organisatie': 'organisatie', 'onderwijs': 'onderwijs', 'voor': 'voor', 'sociale': 'sociale', 'promotie': 'promotie'}\n"
          ]
        }
      ]
    }
  ]
}